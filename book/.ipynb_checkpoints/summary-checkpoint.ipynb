{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe68e74",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# NBS monthly report for October 2024"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "todays_date = str(datetime.now().date())\n",
    "month = datetime.now().strftime(\"%B\")\n",
    "year = str(datetime.now().year)\n",
    "\n",
    "display_markdown('''# NBS monthly report for {month} {year}''')\n",
    "md(\"# NBS monthly report for {} {}\".format(month, year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c8eea",
   "metadata": {},
   "source": [
    "# Quick summary\n",
    "\n",
    "The table below shows a short overview of the NBS performance operation during the last 30 days. The number of products are compared against CDSE. All columns represents the number of products in each portal except the last 3 columns. Those 3 columns represents the data flow from MET Norway to users through the portals where Volumes are measured in Tb. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e505b4f4",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from myst_nb import glue\n",
    "\n",
    "logsdir = pathlib.Path('../data')\n",
    "hubs = ['colhub_global', 'cdse', 'esahub_global', 'colhub_AOI']\n",
    "products = ['S1', 'S2L1C', 'S2L2A', 'S3', 'S5p']\n",
    "\n",
    "data_FE = None\n",
    "for h in hubs:\n",
    "    csvfile = logsdir / f'products_in_{h}.csv'\n",
    "    data_tmp = pd.read_csv(csvfile, header=None, names=['product', 'area', 'sensing_date', f'{h}'], parse_dates=['sensing_date'])\n",
    "    # If several sensing date exist, keep the most recent one\n",
    "    data_clean = copy.deepcopy(data_tmp.drop_duplicates(subset=['sensing_date', 'product', 'area'], keep='last'))\n",
    "    if h == 'colhub_AOI':\n",
    "        data_clean['area'] = 'colhub_aoi'\n",
    "    if data_FE is None:\n",
    "        data_FE = data_clean\n",
    "    else:\n",
    "        data_FE = data_FE.merge(data_clean, on=['sensing_date', 'product', 'area'], how='outer')\n",
    "\n",
    "data = data_FE\n",
    "data.set_index('sensing_date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "mask_s1 = (data['product'] == 'S1') & (data['area'] == 'colhub_aoi')\n",
    "data_s1 = data.loc[mask_s1][-30:][['colhub_global', 'cdse', 'colhub_AOI']].copy()\n",
    "col_s1 = data_s1['colhub_global'].sum()\n",
    "arc_s1 = data_s1['colhub_AOI'].sum()\n",
    "cdse_s1 = data_s1['cdse'].sum()\n",
    "\n",
    "mask_s2l1 = (data['product'] == 'S2L1C') & (data['area'] == 'colhub_aoi')\n",
    "data_s2l1 = data.loc[mask_s2l1][-30:][['colhub_global', 'cdse', 'colhub_AOI']].copy()\n",
    "col_s2l1 = data_s2l1['colhub_global'].sum()\n",
    "arc_s2l1 = data_s2l1['colhub_AOI'].sum()\n",
    "cdse_s2l1 = data_s2l1['cdse'].sum()\n",
    "\n",
    "mask_s2l2 = (data['product'] == 'S2L2A') & (data['area'] == 'colhub_aoi')\n",
    "data_s2l2 = data.loc[mask_s2l2][-30:][['colhub_global', 'cdse', 'colhub_AOI']].copy()\n",
    "col_s2l2 = data_s2l2['colhub_global'].sum()\n",
    "arc_s2l2 = data_s2l2['colhub_AOI'].sum()\n",
    "cdse_s2l2 = data_s2l2['cdse'].sum()\n",
    "\n",
    "mask_s3 = (data['product'] == 'S3') & (data['area'] == 'colhub_aoi')\n",
    "data_s3 = data.loc[mask_s3][-30:][['colhub_global', 'cdse', 'colhub_AOI']].copy()\n",
    "col_s3 = data_s3['colhub_global'].sum()\n",
    "arc_s3 = data_s3['colhub_AOI'].sum()\n",
    "cdse_s3 = data_s3['cdse'].sum()\n",
    "\n",
    "mask_s5 = (data['product'] == 'S5p') & (data['area'] == 'colhub_aoi')\n",
    "data_s5 = data.loc[mask_s5][-30:][['colhub_global', 'cdse', 'colhub_AOI']].copy()\n",
    "col_s5 = data_s5['colhub_global'].sum()\n",
    "arc_s5 = data_s5['colhub_AOI'].sum()\n",
    "cdse_s5 = data_s5['cdse'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659a82a1",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def get_product_type(product):\n",
    "    if product[0:2] == 'S1':\n",
    "        type = product.split('_')[2]\n",
    "    elif product[0:2] == 'S2':\n",
    "        type = product.split('_')[1]\n",
    "        if not type.startswith('M'):\n",
    "            type = 'Unknown'\n",
    "    elif product[0:2] == 'S3':\n",
    "        tmp = product.split('_')\n",
    "        if tmp[1] == 'SL':\n",
    "            type = 'SLSTR_L' + tmp[2]\n",
    "        elif tmp[1] == 'SR':\n",
    "            type = 'SRAL_L' + tmp[2]\n",
    "        elif tmp[1] == 'OL':\n",
    "            type = 'OLCI_L' + tmp[2]\n",
    "        else:\n",
    "            type = 'Unknown'\n",
    "    else:\n",
    "        type = 'Unknown'\n",
    "    if 'DTERRENG' in product:\n",
    "        type = type + '_DTERRENG'\n",
    "    return type\n",
    "\n",
    "def get_data(file):\n",
    "    data = pd.read_csv(file, usecols=[0,1,2,3,4], header=None, names=['download_time', 'user', 'product', 'product_type', 'size', 'download_duration', 'other']\\\n",
    "                        , parse_dates=['download_time'], index_col='download_time')\n",
    "    data['satellite'] = data['product'].apply(lambda x: x[0:2])\n",
    "    data['product_type'] = data['product'].apply(get_product_type)\n",
    "    return data[data['product_type'] != 'Unknown']\n",
    "\n",
    "csvfile = logsdir / 'NBS_frontend-global_outputs.csv'\n",
    "nbs_global = get_data(csvfile)\n",
    "nbs_global.sort_index(inplace=True)\n",
    "nbs_global.fillna(0, inplace=True)\n",
    "nbs_30 = nbs_global.loc[nbs_global.index >= dt.datetime.today() - dt.timedelta(days=30)].copy()\n",
    "\n",
    "col_use = len(nbs_30['user'].unique())\n",
    "col_nb = nbs_30.count()['product_type']\n",
    "col_vol = nbs_30.sum()['size']/1024/1024/1024/1024 #in Tb\n",
    "\n",
    "csvfile = logsdir / 'NBS_frontend-AOI_outputs.csv'\n",
    "nbs_AOI = get_data(csvfile)\n",
    "nbs_AOI.sort_index(inplace=True)\n",
    "nbs_AOI.fillna(0, inplace=True)\n",
    "aoi_30 = nbs_AOI.loc[nbs_AOI.index >= dt.datetime.today() - dt.timedelta(days=30)].copy()\n",
    "\n",
    "arc_use = len(aoi_30['user'].unique())\n",
    "arc_nb = aoi_30.count()['product_type']\n",
    "arc_vol = aoi_30.sum()['size']/1024/1024/1024/1024 #in Tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c774f6d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from myst_nb import glue\n",
    "\n",
    "logsdir = pathlib.Path('../data')\n",
    "\n",
    "def read_dhus_logs_details(file):\n",
    "    data = pd.read_csv(file, header=None, names=['day', 'product_type', 'action', 'volume', 'number', 'timeliness'], \n",
    "                        parse_dates=['day'], index_col=['day'])\n",
    "    return data\n",
    "\n",
    "def read_csv(file):\n",
    "    data_tmp = pd.read_csv(file, header=None, names=['product_type', 'day', 'number', 'volume'], parse_dates=['day'], sep=';')\n",
    "    # If several sensing date exist, keep the numbers only for the most recent script run (ie highest day index)\n",
    "    data_clean = copy.deepcopy(data_tmp.drop_duplicates(subset=['product_type', 'day'], keep='last')).set_index('day').sort_index()\n",
    "    data_clean['volume'] = data_clean['volume'] / 1024. / 1024\n",
    "    return data_clean\n",
    "\n",
    "data_s1 = read_dhus_logs_details(logsdir / 'S1-backend-AOI_inputs.csv')\n",
    "data_s2l1c = read_dhus_logs_details(logsdir / 'S2L1C-backend-AOI_inputs.csv')\n",
    "data_s2l2a = read_dhus_logs_details(logsdir / 'S2L2A-backend-AOI_inputs.csv')\n",
    "data_s3 = read_dhus_logs_details(logsdir / 'S3-backend-AOI_inputs.csv')\n",
    "data_s5 = read_dhus_logs_details(logsdir / 'S5p-backend-AOI_inputs.csv')\n",
    "\n",
    "all_colhub = pd.concat([data_s1, data_s2l1c, data_s2l2a, data_s3, data_s5])\n",
    "\n",
    "csvfile = pathlib.Path('../data/nb_products_volume_per_sensing_date.csv')\n",
    "all_netcdf = read_csv(csvfile)\n",
    "\n",
    "alle = pd.concat([all_colhub, all_netcdf])\n",
    "\n",
    "all_vol_be = alle['volume'].sum() / 1024  # in Tb\n",
    "\n",
    "lately = alle[alle.index >= dt.datetime.today() - dt.timedelta(days=30)]\n",
    "vol_be = lately['volume'].sum() / 1024  # in Tb\n",
    "\n",
    "#nb_be = be_s1 + be_s2l1 + be_s2l2 + be_s3 + be_s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc26074",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8567.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "col_s1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "35878.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "col_s2l1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "35294.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "col_s2l2"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28917.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "col_s3"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15171.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "col_s5"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8574.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "arc_s1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "35632.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "arc_s2l1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "35051.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "arc_s2l2"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28634.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "arc_s3"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15158.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "arc_s5"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "col_use"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "col_nb"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "col_vol"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "arc_use"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "arc_nb"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "arc_vol"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "cdse_s1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "cdse_s2l1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "cdse_s2l2"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "cdse_s3"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "cdse_s5"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "glue(\"col_s1\", col_s1)\n",
    "glue(\"col_s2l1\", col_s2l1)\n",
    "glue(\"col_s2l2\", col_s2l2)\n",
    "glue(\"col_s3\", col_s3)\n",
    "glue(\"col_s5\", col_s5)\n",
    "glue(\"arc_s1\", arc_s1)\n",
    "glue(\"arc_s2l1\", arc_s2l1)\n",
    "glue(\"arc_s2l2\", arc_s2l2)\n",
    "glue(\"arc_s3\", arc_s3)\n",
    "glue(\"arc_s5\", arc_s5)\n",
    "glue(\"col_use\", col_use)\n",
    "glue(\"col_nb\", col_nb)\n",
    "glue(\"col_vol\", col_vol)\n",
    "glue(\"arc_use\", arc_use)\n",
    "glue(\"arc_nb\", arc_nb)\n",
    "glue(\"arc_vol\", arc_vol)\n",
    "glue(\"cdse_s1\", cdse_s1)\n",
    "glue(\"cdse_s2l1\", cdse_s2l1)\n",
    "glue(\"cdse_s2l2\", cdse_s2l2)\n",
    "glue(\"cdse_s3\", cdse_s3)\n",
    "glue(\"cdse_s5\", cdse_s5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99769f48",
   "metadata": {},
   "source": [
    "| Portals | S1 | S2L1C | S2L2A | S3 | S5p | Nb of users | Nb of products | Volume |\n",
    "|:---------:|:---------:|:--------:|:---------:|:----------:|:----------:|:-------------:|:---------:|:----------:|\n",
    "| colhub.met.no | {glue:text}`col_s1:.0f` | {glue:text}`col_s2l1:.0f` | {glue:text}`col_s2l2:.0f` | {glue:text}`col_s3:.0f` | {glue:text}`col_s5:.0f` | {glue:text}`col_use` | {glue:text}`col_nb` | {glue:text}`col_vol:.3f` |\n",
    "| colhub-archive.met.no | {glue:text}`arc_s1:.0f` | {glue:text}`arc_s2l1:.0f` | {glue:text}`arc_s2l2:.0f` | {glue:text}`arc_s3:.0f` | {glue:text}`arc_s5:.0f` | {glue:text}`arc_use` | {glue:text}`arc_nb` | {glue:text}`arc_vol:.3f` |\n",
    "| dataspace.copernicus.eu | {glue:text}`cdse_s1:.0f` | {glue:text}`cdse_s2l1:.0f` | {glue:text}`cdse_s2l2:.0f` | {glue:text}`cdse_s3:.0f` | {glue:text}`cdse_s5:.0f` |  | | |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "639eaf17",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Finally, the total amount of disk space dedicated to the NBS project, including either products in SAFE and NetCDF formats, represents 5962 Tb."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(\"Finally, the total amount of disk space dedicated to the NBS project, including either products in SAFE and NetCDF formats, represents {} Tb.\".format(int(all_vol_be)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c1d3ee",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Monthly volumes (in Tb)\n",
    "lately = alle[alle.index >= dt.datetime.today() - dt.timedelta(days=365)]\n",
    "year = (lately['volume'].sum()/1024.)\n",
    "after_year = year + all_vol_be\n",
    "short = lately[lately.index <= dt.datetime.today() - dt.timedelta(days=123)]\n",
    "m6 = (short['volume'].sum()/1024.)\n",
    "after_6m = m6 + all_vol_be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df449b93",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Due to tracking the data ingested and produced for the NBS project in the last year it is possible to forecast the upcoming need for disk space. As long as data flows follows the same pattern than last year, in 6 months the total disk space will grow until 6525 Tb; while in 12 months it is forecast to become 6913 Tb."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(\"Due to tracking the data ingested and produced for the NBS project in the last year it is possible to forecast the upcoming need for disk space. As long as data flows follows the same pattern than last year, in 6 months the total disk space will grow until {} Tb; while in 12 months it is forecast to become {} Tb.\".format(int(after_6m), int(after_year)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
